#!/usr/bin/env python3
"""
PDF å¤„ç†å™¨ - ç®€åŒ–ç‰ˆ

åŠŸèƒ½ï¼š
1. æ‰«æ PDF æ–‡ä»¶
2. ä½¿ç”¨ MinerU API è½¬æ¢ä¸º Markdown
3. çŠ¶æ€è·Ÿè¸ªï¼ˆæ‘˜è¦ç”± Claude Code ç›´æ¥ç”Ÿæˆï¼‰
4. æ–­ç‚¹ç»­ä¼ 
"""

import os
import csv
import json
import time
import logging
import io
import tempfile
import zipfile
import threading
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, as_completed
import requests
from dotenv import load_dotenv

# æ˜ç¡®æŒ‡å®š .env æ–‡ä»¶è·¯å¾„
dotenv_path = Path('/workspaces/Skills_demo/.env')
load_dotenv(dotenv_path=str(dotenv_path))

logger = logging.getLogger(__name__)


# =============================================================================
# å¤„ç†çŠ¶æ€
# =============================================================================

@dataclass
class ProcessingResult:
    """å¤„ç†ç»“æœ"""
    filename: str
    md_converted: bool = False
    summary_generated: bool = False
    md_path: Optional[str] = None
    images_dir: Optional[str] = None
    summary_path: Optional[str] = None
    error_message: Optional[str] = None
    processing_time: float = 0.0
    md_file_reused: bool = False

    def to_dict(self) -> Dict:
        return {
            'filename': self.filename,
            'md_converted': self.md_converted,
            'summary_generated': self.summary_generated,
            'md_path': self.md_path,
            'images_dir': self.images_dir,
            'summary_path': self.summary_path,
            'error_message': self.error_message,
            'processing_time': self.processing_time,
            'md_file_reused': self.md_file_reused
        }


# =============================================================================
# MinerU å®¢æˆ·ç«¯ - å‚è€ƒ pdf_to_bib_processor.py çš„å®ç°
# =============================================================================

class MinerUClient:
    """åŸºäºå®˜æ–¹å®ç°çš„ MinerU API å®¢æˆ·ç«¯"""

    def __init__(self, api_key: str):
        """åˆå§‹åŒ–å®¢æˆ·ç«¯"""
        self.api_key = api_key
        self.api_base = "https://mineru.net/api/v4"
        self.headers = {
            'Authorization': f'Bearer {api_key}'
        }
        self.max_retries = 4
        self.retry_delay = 5
        self.request_timeout = 180

    def test_connection(self, force: bool = False) -> bool:
        """æµ‹è¯• API è¿æ¥"""
        # æ¯æ¬¡éƒ½é‡æ–°æµ‹è¯•ï¼Œå› ä¸º API key å¯èƒ½å·²æ›´æ–°
        # ç§»é™¤ç¼“å­˜ä»¥ç¡®ä¿ä½¿ç”¨æœ€æ–°çš„å‡­æ®

        print("ğŸ”— æµ‹è¯• MinerU API è¿æ¥...")

        # å°è¯•è·å–ä¸Šä¼ é“¾æ¥æ¥æµ‹è¯•è®¤è¯
        test_data = {
            "enable_formula": False,
            "language": "ch",
            "enable_table": True,
            "files": [{"name": "test.pdf", "is_ocr": True}]
        }

        try:
            url = f"{self.api_base}/file-urls/batch"
            headers = self.headers.copy()
            headers['Content-Type'] = 'application/json'

            response = requests.post(url, headers=headers, json=test_data, timeout=30)

            if response.status_code == 200:
                result = response.json()
                if result.get('code') == 0:
                    print("âœ… MinerU API è¿æ¥æˆåŠŸï¼")
                    return True
                else:
                    print(f"âŒ API è¿”å›é”™è¯¯: {result.get('msg', 'Unknown error')}")
            elif response.status_code == 401:
                print("âŒ 401 è®¤è¯å¤±è´¥ - API å¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸ")
            else:
                print(f"âŒ HTTP é”™è¯¯: {response.status_code}")

        except Exception as e:
            print(f"âŒ è¿æ¥å¼‚å¸¸: {e}")

        print("ğŸ’¡ å»ºè®®ï¼šè®¿é—® https://mineru.net/apiManage æ£€æŸ¥ API å¯†é’¥")
        return False

    def _get_upload_url(self, filename: str, **kwargs) -> Dict[str, str]:
        """è·å–æ–‡ä»¶ä¸Šä¼ é“¾æ¥"""
        url = f"{self.api_base}/file-urls/batch"
        data = {
            "enable_formula": kwargs.get('enable_formula', False),
            "language": kwargs.get('language', 'ch'),
            "enable_table": kwargs.get('enable_table', True),
            "files": [{"name": filename, "is_ocr": kwargs.get('is_ocr', True)}]
        }

        headers = self.headers.copy()
        headers['Content-Type'] = 'application/json'

        response = requests.post(url, headers=headers, json=data, timeout=self.request_timeout)
        response.raise_for_status()

        result = response.json()
        if result.get('code') != 0:
            raise Exception(f"API è¿”å›é”™è¯¯: {result.get('msg', 'Unknown error')}")

        batch_id = result['data']['batch_id']
        file_url = result['data']['file_urls'][0]
        logger.info(f"è·å–ä¸Šä¼ é“¾æ¥æˆåŠŸï¼Œæ‰¹æ¬¡ID: {batch_id}")
        return {'batch_id': batch_id, 'file_url': file_url}

    def _upload_file_to_url(self, file_path: Path, upload_url: str) -> bool:
        """å°†æ–‡ä»¶ä¸Šä¼ åˆ°æŒ‡å®š URL"""
        with open(file_path, 'rb') as f:
            response = requests.put(upload_url, data=f, timeout=self.request_timeout)
            response.raise_for_status()
            logger.info(f"æ–‡ä»¶ {file_path.name} ä¸Šä¼ æˆåŠŸ")
            return True

    def get_batch_result(self, batch_id: str) -> Optional[Dict]:
        """è·å–æ‰¹é‡ä»»åŠ¡ç»“æœ"""
        url = f"{self.api_base}/extract-results/batch/{batch_id}"
        response = requests.get(url, headers=self.headers, timeout=self.request_timeout)
        response.raise_for_status()

        result = response.json()
        if result.get('code') != 0:
            raise Exception(f"è·å–æ‰¹é‡ç»“æœå¤±è´¥: {result.get('msg', 'Unknown error')}")

        return result['data']

    def wait_for_completion(self, batch_id: str, max_wait_time: int = 300) -> Optional[str]:
        """ç­‰å¾…æ‰¹é‡ä»»åŠ¡å®Œæˆå¹¶è¿”å›ç»“æœ URL"""
        start_time = time.time()
        check_interval = 10
        last_status_log_time = 0

        logger.info(f"å¼€å§‹ç­‰å¾… MinerU API å¤„ç†æ–‡ä»¶ï¼Œæ‰¹æ¬¡ID: {batch_id}")

        while time.time() - start_time < max_wait_time:
            try:
                result = self.get_batch_result(batch_id)
                if result and result.get('extract_result'):
                    extract_result = result['extract_result'][0]
                    state = extract_result.get('state')
                    current_time = time.time()

                    if state == 'done':
                        logger.info("ğŸ‰ PDF å¤„ç†å®Œæˆï¼")
                        return extract_result.get('full_zip_url')
                    elif state == 'failed':
                        error_msg = extract_result.get('err_msg', 'Unknown error')
                        logger.error(f"âŒ PDF å¤„ç†å¤±è´¥: {error_msg}")
                        raise Exception(f"PDF å¤„ç†å¤±è´¥: {error_msg}")
                    elif state in ['pending', 'running', 'converting']:
                        if current_time - last_status_log_time >= 30:
                            elapsed_time = int(current_time - start_time)
                            logger.info(f"â³ PDF å¤„ç†çŠ¶æ€: {state} (å·²ç­‰å¾… {elapsed_time}s)")
                            last_status_log_time = current_time
                    else:
                        logger.warning(f"âš ï¸ æœªçŸ¥çš„å¤„ç†çŠ¶æ€: {state}")

            except Exception as e:
                if "PDF å¤„ç†å¤±è´¥" in str(e):
                    raise
                logger.warning(f"æ£€æŸ¥å¤„ç†çŠ¶æ€æ—¶å‡ºé”™: {e}ï¼Œå°†é‡è¯•...")

            time.sleep(check_interval)

        elapsed_minutes = int((time.time() - start_time) / 60)
        logger.error(f"âŒ PDF å¤„ç†è¶…æ—¶ï¼å·²ç­‰å¾… {elapsed_minutes} åˆ†é’Ÿ")
        raise Exception(f"PDF å¤„ç†è¶…æ—¶ï¼Œå·²ç­‰å¾… {elapsed_minutes} åˆ†é’Ÿ")

    def download_result(self, download_url: str, output_dir: Path, pdf_name: str) -> Tuple[bool, str, str]:
        """ä¸‹è½½è§£æç»“æœ"""
        response = requests.get(download_url, timeout=300)
        response.raise_for_status()

        with tempfile.TemporaryDirectory() as temp_dir:
            with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:
                zip_file.extractall(temp_dir)

                # æŸ¥æ‰¾ markdown æ–‡ä»¶
                md_files = []
                for root, dirs, files in os.walk(temp_dir):
                    for file in files:
                        if file.endswith('.md'):
                            md_files.append(os.path.join(root, file))

                if not md_files:
                    raise Exception("ZIP æ–‡ä»¶ä¸­æœªæ‰¾åˆ° Markdown æ–‡ä»¶")

                # åˆ›å»ºè¾“å‡ºç›®å½•
                md_output_dir = output_dir / "md"
                md_output_dir.mkdir(parents=True, exist_ok=True)

                # å¤åˆ¶ç¬¬ä¸€ä¸ª markdown æ–‡ä»¶
                src_md = md_files[0]
                pdf_stem = Path(pdf_name).stem
                dst_md = md_output_dir / f"{pdf_stem}.md"

                with open(src_md, 'r', encoding='utf-8') as f:
                    content = f.read()
                with open(dst_md, 'w', encoding='utf-8') as f:
                    f.write(content)

                logger.info(f"Markdown æ–‡ä»¶å·²ä¿å­˜åˆ°: {dst_md}")

                # å¤åˆ¶ images æ–‡ä»¶å¤¹
                images_dst = output_dir / "imgs" / pdf_stem
                images_src = None
                images_count = 0

                # æŸ¥æ‰¾ images ç›®å½•
                for root, dirs, files in os.walk(temp_dir):
                    if 'images' in dirs:
                        images_src = os.path.join(root, 'images')
                        logger.info(f"æ‰¾åˆ° images ç›®å½•: {images_src}")
                        break

                if images_src and os.path.exists(images_src):
                    images_dst.mkdir(parents=True, exist_ok=True)
                    image_files = os.listdir(images_src)
                    logger.info(f"å›¾ç‰‡æ–‡ä»¶æ•°: {len(image_files)}")

                    for file in image_files:
                        src_file = os.path.join(images_src, file)
                        dst_file = images_dst / file
                        if os.path.isfile(src_file):
                            with open(src_file, 'rb') as f:
                                content = f.read()
                            with open(dst_file, 'wb') as f:
                                f.write(content)
                            images_count += 1

                    logger.info(f"å·²æå– {images_count} ä¸ªå›¾ç‰‡æ–‡ä»¶åˆ°: {images_dst}")
                else:
                    logger.warning("æœªæ‰¾åˆ° images ç›®å½•")

                images_dst_str = str(images_dst) if images_count > 0 else ""
                return True, str(dst_md), images_dst_str

        return False, "", ""

    def convert(self, pdf_path: str, output_dir: Path = None) -> Tuple[bool, str, str]:
        """è½¬æ¢ PDF åˆ° Markdownï¼ˆå®Œæ•´æµç¨‹ï¼Œè¿”å› MD è·¯å¾„å’Œå›¾ç‰‡è·¯å¾„ï¼‰"""
        pdf_file = Path(pdf_path)
        # ä½¿ç”¨ä¼ å…¥çš„ output_dirï¼Œå¦‚æœæœªä¼ å…¥åˆ™ä½¿ç”¨ PDF çˆ¶ç›®å½•çš„ processed
        if output_dir is None:
            output_dir = pdf_file.parent / "processed"
        else:
            output_dir = Path(output_dir)

        try:
            logger.info(f"å¼€å§‹å¤„ç† PDF æ–‡ä»¶: {pdf_file}")

            if not pdf_file.exists():
                raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {pdf_file}")

            file_size_mb = pdf_file.stat().st_size / (1024 * 1024)
            logger.info(f"æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")

            # 1. è·å–ä¸Šä¼ é“¾æ¥
            logger.info("æ­£åœ¨è·å–ä¸Šä¼ é“¾æ¥...")
            upload_info = self._get_upload_url(pdf_file.name)
            batch_id = upload_info['batch_id']
            upload_url = upload_info['file_url']

            # 2. ä¸Šä¼ æ–‡ä»¶
            logger.info("æ­£åœ¨ä¸Šä¼ æ–‡ä»¶...")
            self._upload_file_to_url(pdf_file, upload_url)

            # 3. ç­‰å¾…å¤„ç†å®Œæˆ
            logger.info("æ­£åœ¨ç­‰å¾…å¤„ç†å®Œæˆ...")
            download_url = self.wait_for_completion(batch_id, 300)

            if not download_url:
                raise Exception("å¤„ç†å¤±è´¥æˆ–è¶…æ—¶")

            # 4. ä¸‹è½½ç»“æœ
            logger.info("æ­£åœ¨ä¸‹è½½ç»“æœ...")
            success, md_path, images_dir = self.download_result(download_url, output_dir, pdf_file.name)

            if success:
                logger.info(f"âœ… PDF å¤„ç†å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {md_path}")
                if images_dir:
                    logger.info(f"ğŸ“ å›¾ç‰‡å·²ä¿å­˜åˆ°: {images_dir}")
                return success, md_path, images_dir
            return False, "", ""

        except Exception as e:
            logger.error(f"MinerU è½¬æ¢å¼‚å¸¸: {e}")
            return False, "", ""


# =============================================================================
# PDF å¤„ç†å™¨
# =============================================================================

class PDFProcessor:
    """PDF å¤„ç†å™¨"""

    def __init__(self, config: Dict):
        self.pdf_dir = Path(config.get('pdf_dir', '01_articles'))
        self.output_dir = Path(config.get('output_dir', '01_articles/processed'))
        self.status_file = Path(config.get('status_file', '.info/.pdf_processing_status.csv'))

        api_key = config.get('mineru_api_key', os.getenv('MINERU_API_KEY'))
        self.mineru_client = MinerUClient(api_key)

        self.status: Dict[str, Dict] = {}
        self._print_lock = threading.Lock()

        self.max_workers = int(config.get('max_workers', 5))
        self.enable_parallel = config.get('enable_parallel', True)

        self._load_status()

    def _load_status(self):
        """åŠ è½½å¤„ç†çŠ¶æ€"""
        if self.status_file.exists():
            with open(self.status_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    self.status[row['filename']] = row

    def _save_status(self):
        """ä¿å­˜å¤„ç†çŠ¶æ€"""
        with open(self.status_file, 'w', encoding='utf-8', newline='') as f:
            if self.status:
                fieldnames = list(list(self.status.values())[0].keys())
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(self.status.values())

    def get_expected_md_path(self, filename: str) -> Path:
        return self.output_dir / 'md' / f"{Path(filename).stem}.md"

    def get_expected_summary_path(self, filename: str) -> Path:
        return self.output_dir / 'summaries' / f"{Path(filename).stem}.json"

    def is_md_file_valid(self, pdf_path: Path) -> Tuple[bool, str]:
        """æ£€æŸ¥ MD æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ"""
        md_path = self.get_expected_md_path(pdf_path.name)

        if not md_path.exists():
            return False, "MD æ–‡ä»¶ä¸å­˜åœ¨"

        if md_path.stat().st_size < 100:
            return False, "MD æ–‡ä»¶è¿‡å°"

        try:
            with open(md_path, 'r', encoding='utf-8') as f:
                content = f.read()
                if len(content.strip()) < 50:
                    return False, "MD æ–‡ä»¶å†…å®¹è¿‡å°‘"
        except Exception as e:
            return False, f"è¯»å– MD æ–‡ä»¶å¤±è´¥: {e}"

        return True, "MD æ–‡ä»¶æœ‰æ•ˆ"

    def get_expected_images_dir(self, filename: str) -> Path:
        """è·å–é¢„æœŸçš„å›¾ç‰‡ç›®å½•"""
        return self.output_dir / 'imgs' / Path(filename).stem

    def process_single_pdf(self, pdf_path: Path) -> ProcessingResult:
        """å¤„ç†å•ä¸ª PDF"""
        result = ProcessingResult(filename=pdf_path.name)
        start = time.time()

        try:
            md_path = self.get_expected_md_path(pdf_path.name)
            summary_path = self.get_expected_summary_path(pdf_path.name)

            # 1. æ£€æŸ¥æ˜¯å¦å·²æœ‰æœ‰æ•ˆçš„ MD æ–‡ä»¶
            md_valid, md_message = self.is_md_file_valid(pdf_path)
            if md_valid:
                result.md_converted = True
                result.md_file_reused = True
                result.md_path = str(md_path)
                # æ£€æŸ¥å›¾ç‰‡ç›®å½•
                images_dir = self.output_dir / 'imgs' / pdf_path.stem
                if images_dir.exists():
                    result.images_dir = str(images_dir)
                logger.info(f"é‡ç”¨ç°æœ‰ MD: {pdf_path.name}")
            else:
                # 2. æµ‹è¯•è¿æ¥å¹¶è½¬æ¢
                if self.mineru_client.test_connection():
                    logger.info(f"MD æ–‡ä»¶æ— æ•ˆ: {md_message}ï¼Œå¼€å§‹è½¬æ¢...")
                    # download_result å·²åœ¨ç£ç›˜å†™å…¥æ–‡ä»¶ï¼Œè¿”å›çš„æ˜¯ md_path å’Œ images_dir
                    success, md_path, images_dir = self.mineru_client.convert(str(pdf_path), self.output_dir)
                    if success:
                        # MD æ–‡ä»¶å·²ç”± download_result ä¿å­˜ï¼Œæ— éœ€å†æ¬¡å†™å…¥
                        result.md_converted = True
                        result.md_path = str(md_path)
                        result.images_dir = images_dir if images_dir else None
                        logger.info(f"MD è½¬æ¢æˆåŠŸ: {pdf_path.name}")
                        logger.info(f"MD æ–‡ä»¶è·¯å¾„: {md_path}")
                        if images_dir:
                            logger.info(f"å›¾ç‰‡ç›®å½•: {images_dir}")
                    else:
                        result.error_message = "Markdown è½¬æ¢å¤±è´¥"
                        return result
                else:
                    result.error_message = "MinerU API è¿æ¥å¤±è´¥"
                    return result

            # 3. æ£€æŸ¥æ‘˜è¦çŠ¶æ€
            result.summary_generated = summary_path.exists()
            result.summary_path = str(summary_path)

        except Exception as e:
            result.error_message = str(e)
            logger.error(f"å¤„ç†å¼‚å¸¸: {e}")

        finally:
            result.processing_time = time.time() - start
            self.status[pdf_path.name] = result.to_dict()
            self._save_status()

        return result

    def process_all_pdfs(self) -> List[ProcessingResult]:
        """å¤„ç†æ‰€æœ‰ PDF"""
        if not self.pdf_dir.exists():
            logger.error(f"PDF ç›®å½•ä¸å­˜åœ¨: {self.pdf_dir}")
            return []

        pdf_files = list(self.pdf_dir.glob("*.pdf"))
        if not pdf_files:
            logger.info("æ²¡æœ‰æ‰¾åˆ° PDF æ–‡ä»¶")
            return []

        if self.enable_parallel and len(pdf_files) > 1:
            return self._process_parallel(pdf_files)
        return self._process_sequential(pdf_files)

    def _process_sequential(self, pdf_files: List[Path]) -> List[ProcessingResult]:
        """ä¸²è¡Œå¤„ç†"""
        results = []
        for pdf_path in pdf_files:
            result = self.process_single_pdf(pdf_path)
            results.append(result)
            self._print_result(result)
        return results

    def _process_parallel(self, pdf_files: List[Path]) -> List[ProcessingResult]:
        """å¹¶è¡Œå¤„ç†"""
        results = []
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = {executor.submit(self.process_single_pdf, p): p for p in pdf_files}
            for future in as_completed(futures):
                result = future.result()
                results.append(result)
                self._print_result(result)
        return sorted(results, key=lambda r: r.filename)

    def _print_result(self, result: ProcessingResult):
        """æ‰“å°ç»“æœ"""
        with self._print_lock:
            status = "âœ…" if result.md_converted else "âŒ"
            summary_mark = " ğŸ“" if result.summary_generated else ""
            reused = " (é‡ç”¨)" if result.md_file_reused else ""
            images_mark = f" ğŸ–¼ï¸" if result.images_dir else ""
            error_msg = f" [{result.error_message}]" if result.error_message else ""
            print(f"{status} {result.filename}{reused}{summary_mark}{images_mark}{error_msg} ({result.processing_time:.1f}s)")

    def generate_report(self, results: List[ProcessingResult]):
        """ç”ŸæˆæŠ¥å‘Š"""
        if not results:
            print("\næ²¡æœ‰ PDF æ–‡ä»¶éœ€è¦å¤„ç†")
            return

        total = len(results)
        md_converted = sum(1 for r in results if r.md_converted)
        summary_generated = sum(1 for r in results if r.summary_generated)
        images_extracted = sum(1 for r in results if r.images_dir)

        print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           PDF å¤„ç†æŠ¥å‘Š                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š ç»Ÿè®¡ä¿¡æ¯
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æ€»æ–‡ä»¶æ•°:        {total}
MD è½¬æ¢æˆåŠŸ:     {md_converted} ({md_converted/total*100:.1f}%)
æ‘˜è¦ç”ŸæˆæˆåŠŸ:    {summary_generated}
å›¾ç‰‡æå–æˆåŠŸ:    {images_extracted}

ğŸ“ å¤„ç†ç»“æœ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
MD ç›®å½•:   {self.output_dir}/md/
å›¾ç‰‡ç›®å½•: {self.output_dir}/imgs/
æ‘˜è¦ç›®å½•: {self.output_dir}/summaries/

ğŸ“„ æ–‡ä»¶è¯¦æƒ…
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”""")

        for r in results:
            status = "âœ…" if r.md_converted else "âŒ"
            summary = " + ğŸ“" if r.summary_generated else ""
            reused = " (é‡ç”¨)" if r.md_file_reused else ""
            images = f" ğŸ–¼ï¸" if r.images_dir else ""
            error = f" [{r.error_message}]" if r.error_message else ""
            print(f"{status} {r.filename}{reused}{summary}{images}{error}")


def main():
    """ä¸»å‡½æ•°"""
    config = {
        'pdf_dir': os.getenv('PDF_DIR', '01_articles'),
        'output_dir': os.getenv('OUTPUT_DIR', '01_articles/processed'),
        'status_file': os.getenv('STATUS_FILE', '.info/.pdf_processing_status.csv'),
        'mineru_api_key': os.getenv('MINERU_API_KEY'),
        'max_workers': int(os.getenv('PDF_MAX_WORKERS', '5')),
        'enable_parallel': os.getenv('PDF_ENABLE_PARALLEL', 'true').lower() == 'true',
    }

    print(f"ğŸ“ PDF ç›®å½•: {config['pdf_dir']}")
    print(f"ğŸ”„ å¹¶è¡Œå¤„ç†: {'å¯ç”¨' if config['enable_parallel'] else 'ç¦ç”¨'}")
    print()

    processor = PDFProcessor(config)
    results = processor.process_all_pdfs()
    processor.generate_report(results)


if __name__ == "__main__":
    main()
